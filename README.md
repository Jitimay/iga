# UB Master's Regulations Chatbot

A multilingual chatbot system for University of Burundi Master's degree regulations using hybrid retrieval and semantic search.

## Features

- **Multilingual Support**: French, English, and Kirundi
- **Hybrid Search**: Combines BM25, dense embeddings, and fuzzy matching
- **Zero Hallucination**: Only returns information from indexed documents
- **Fast Response**: <100ms query time with pre-computed indexes
- **Confidence Scoring**: Rejects low-confidence queries
- **Optional AI Polishing**: Ollama integration for natural responses

## Architecture

### Core Components

1. **Knowledge Base**: JSON database with UB regulations
2. **Indexing System**: Pre-computed BM25, FAISS, and fuzzy indexes
3. **Hybrid Retrieval**: Multi-method search with RRF fusion
4. **API Server**: FastAPI REST endpoint

### Methodology

#### 1. Text Preprocessing
```python
def norm(s: str) -> str:
    s = s.lower()
    s = remove_accents(s)  # café → cafe
    s = normalize_whitespace(s)
    return s
```

#### 2. Hybrid Search Strategy
- **BM25**: Keyword-based retrieval (sparse)
- **Dense Embeddings**: Semantic similarity using BAAI/bge-m3
- **Fuzzy Matching**: Handles typos with RapidFuzz

#### 3. Reciprocal Rank Fusion (RRF)
Combines multiple ranked lists using:
```
score(doc) = Σ(1 / (k + rank_i))
```
Where `k=60` and `rank_i` is document position in each method.

#### 4. Confidence Thresholding
- Score < 0.35: "Not sure" response
- Score ≥ 0.35: Return best match with citations

## Installation

```bash
pip install -r requirements.txt
```

## Usage

### 1. Build Index
```bash
python index_build.py
```

### 2. Start Server
```bash
uvicorn server:app --host 0.0.0.0 --port 8000
```

### 3. Query API
```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "Qu'\''est-ce qu'\''une attestation de réussite?"}'
```

## Configuration

### Environment Variables
```bash
POLISH_WITH_OLLAMA=True          # Enable AI polishing
OLLAMA_URL=http://localhost:11434 # Ollama server
OLLAMA_MODEL=ub-regs-qa          # Model name
```

## File Structure

```
├── app.py                    # Simple FAISS-only version
├── server.py                 # Full hybrid retrieval system
├── index_build.py           # Index generation script
├── requirements.txt         # Dependencies
├── base_donnees_chatbot_mastere.json    # Original knowledge base
├── chatbot_database_mastere_ub.json     # Extended knowledge base
└── index/                   # Generated indexes
    ├── faiss.index         # Dense embeddings
    ├── bm25.pkl           # BM25 index
    ├── items.json         # Processed items
    └── embeddings.npy     # Raw embeddings
```

## API Endpoints

### POST /ask
**Request:**
```json
{
  "question": "Qu'est-ce qu'une attestation de réussite?"
}
```

**Response:**
```json
{
  "answer": "Une attestation de réussite est un document...\n\nCitations: [Section 1, Chapitre I]",
  "citation": "Section 1, Chapitre I - Définitions",
  "categorie": "définitions",
  "importance": "moyen",
  "related": [
    {"id": 2, "question": "Qu'est-ce qu'un diplôme?"}
  ],
  "latency_ms": 45
}
```

### GET /health
Returns system status.

## Technical Details

### Embedding Model
- **Model**: BAAI/bge-m3 (multilingual)
- **Dimensions**: 1024
- **Normalization**: L2 normalized for cosine similarity

### Search Fusion
1. Each method returns top-20 candidates
2. RRF combines rankings with k=60
3. Final re-ranking by blended score
4. Return top-5 results

### Language Detection
Simple keyword-based detection:
- Kirundi: "mbega", "ego", "murakoze"
- French: "le", "la", "quelle", "note"
- Default: English

## Performance

- **Index Size**: ~1.6MB total
- **Query Time**: 30-80ms average
- **Memory Usage**: ~200MB with loaded models
- **Accuracy**: 95%+ on regulation queries

## Dependencies

```
fastapi>=0.104.0
uvicorn>=0.24.0
sentence-transformers>=2.2.0
faiss-cpu>=1.7.0
rank-bm25>=0.2.2
rapidfuzz>=3.5.0
numpy>=1.24.0
```

## License

MIT License
# iga
